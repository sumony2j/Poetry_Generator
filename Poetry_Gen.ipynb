{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOalQSv66kfY"
   },
   "source": [
    "## *Poetry Generation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q07IeVKY9q41"
   },
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nq7smoqK9wMT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmiDhUNd6wP4"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JnVa4LGRze31"
   },
   "outputs": [],
   "source": [
    "Data = requests.get('https://raw.githubusercontent.com/laxmimerit/poetry-data/master/adele.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FhkpqhGQ-CVh"
   },
   "outputs": [],
   "source": [
    "Data = Data.split(sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGTj6kzw-EVe",
    "outputId": "d124a811-037d-41ed-f455-c174e947657f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tq_3Oq0t_Y89",
    "outputId": "a3ed4d12-79d2-447e-b02b-3f526c213514"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_line_size = max(len(x.split(sep=\" \")) for x in Data)\n",
    "max_line_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5eFVWlc_qTt",
    "outputId": "f8f334ca-a772-4f78-91f3-20a9ce2b5751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's in my blood and I stain every heart that I use to heal the pain So I blame it on the River Lea, the River Lea, the River Lea\n"
     ]
    }
   ],
   "source": [
    "for x in Data:\n",
    "    if len(x.split(sep=\" \"))==30:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nQu5rNeMakJv"
   },
   "outputs": [],
   "source": [
    "Input_Data = [\"starttoken \" + i for i in Data]\n",
    "#Input_Data = [i.split(\" \") for i in Input_Data_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-ZNg9L2ma-9l"
   },
   "outputs": [],
   "source": [
    "Output_Data = [i + \" endtoken\" for i in Data]\n",
    "#Output_Data = [i.split(\" \") for i in Output_Data_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXLEr53myMa4",
    "outputId": "40ac62ea-251c-44ba-834d-02cf351488b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"starttoken Let's just say that maybe\", \"It's more than enough endtoken\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_Data[5],Output_Data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hrIqPPX8bPY1"
   },
   "outputs": [],
   "source": [
    "Dataset = Input_Data + Output_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vxisxHVRvrW4",
    "outputId": "36b64271-9ac4-4f82-971f-0c4b1539a3c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"starttoken It's more than enough\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iy7AcL1RCKjV"
   },
   "outputs": [],
   "source": [
    "VOC_SIZE = 20000\n",
    "OUTPUT_SEQ = 64\n",
    "EMBEDDING_DIM =50\n",
    "LATENT_DIM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bY-K5znC_7Ml"
   },
   "outputs": [],
   "source": [
    "vect = keras.layers.TextVectorization(max_tokens=VOC_SIZE,standardize='lower_and_strip_punctuation',\n",
    "                                      output_mode='int',output_sequence_length=OUTPUT_SEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nnYXu1BGAksf"
   },
   "outputs": [],
   "source": [
    "vect.adapt(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ibytlxVGCxAg"
   },
   "outputs": [],
   "source": [
    "encoded_input = vect(Input_Data)\n",
    "encoded_output = vect(Output_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Kqdea5RiC1fj",
    "outputId": "87a42ca8-ed0f-4c4a-ac6c-24f3a5a54903"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maybe'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_vocabulary()[235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rpe649Tj3Cnz"
   },
   "outputs": [],
   "source": [
    "Num_Words = len(vect.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22CALRDn6oYe",
    "outputId": "e9d84c9f-5fce-4c0c-ed68-c902a974618a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vect.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1L_ZD8_VdRMb",
    "outputId": "68a80836-9376-4a18-b192-8ff6572dff19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"starttoken Let's just say that maybe\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_Data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uck2D-xcC671",
    "outputId": "5e9d5b88-3416-4401-8552-29bf73f87203"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
       "array([  2, 296,  38,  49,  13, 235,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuQyP8r8a1an",
    "outputId": "95d1b9d3-d54d-4bb0-f78c-f14fa34516fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2400, 64]), 2400)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape, len(encoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y25M87VbDe5"
   },
   "source": [
    "### Hot-Encode Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YWTdWp-jbH9i"
   },
   "outputs": [],
   "source": [
    "target_data = np.zeros((len(encoded_output),OUTPUT_SEQ,Num_Words))\n",
    "for i,target in enumerate(encoded_output):\n",
    "    for j,word in enumerate(target):\n",
    "        if word>0:\n",
    "            target_data[i,j,word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c-lXpUDdDhZ",
    "outputId": "5d03a1c8-6945-4b66-c26e-43f2419c4ae9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
       "array([120,  11,  82, 159,   6, 140,   3,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fm40PQhObIfW",
    "outputId": "9d3c5aad-a764-4ae6-8e93-0cf964da9fc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data[1,0,120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMswW1mGdX5Y"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DPoj9TLWd7qS"
   },
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=(OUTPUT_SEQ,))\n",
    "initial_h = keras.layers.Input(shape=(LATENT_DIM,))\n",
    "initial_c = keras.layers.Input(shape=(LATENT_DIM,))\n",
    "emb = keras.layers.Embedding(VOC_SIZE,EMBEDDING_DIM)\n",
    "x = emb(input_)\n",
    "lstm = keras.layers.LSTM(LATENT_DIM,return_sequences=True,return_state=True)\n",
    "x,_,_ = lstm(x,initial_state=[initial_h,initial_c])\n",
    "dense_1 = keras.layers.Dense(256,activation='relu')\n",
    "dense = dense_1(x)\n",
    "dense_2 = keras.layers.Dense(Num_Words,activation=\"softmax\")\n",
    "output = dense_2(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uLL7dw-Teg0l"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Model([input_,initial_h,initial_c],output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "c5GCcDcbrHdH"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='CategoricalCrossentropy',metrics=['acc'],optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kpp1xvSqrtNL",
    "outputId": "0bd89c12-3524-4325-96aa-e3f4c78c62d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 64, 50)       1000000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 64, 25),     7600        ['embedding[0][0]',              \n",
      "                                 (None, 25),                      'input_2[0][0]',                \n",
      "                                 (None, 25)]                      'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64, 256)      6656        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64, 1384)     355688      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,369,944\n",
      "Trainable params: 1,369,944\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMCQU7Izi-4y",
    "outputId": "b133d3e5-01c4-4acd-fc68-dcf502cf4085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros((len(encoded_input),LATENT_DIM))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X115yXRAsePc",
    "outputId": "aab98f59-cc3d-42ce-fa90-9e8f1a302626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - 26s 119ms/step - loss: 1.0383 - acc: 0.0126 - val_loss: 0.8642 - val_acc: 0.0156\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 1.0172 - acc: 0.0156 - val_loss: 0.8274 - val_acc: 0.0156\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.9345 - acc: 0.0156 - val_loss: 0.7619 - val_acc: 0.0156\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.8833 - acc: 0.0156 - val_loss: 0.7405 - val_acc: 0.0156\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.8710 - acc: 0.0156 - val_loss: 0.7353 - val_acc: 0.0156\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.8662 - acc: 0.0156 - val_loss: 0.7331 - val_acc: 0.0156\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.8629 - acc: 0.0156 - val_loss: 0.7291 - val_acc: 0.0156\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.8585 - acc: 0.0156 - val_loss: 0.7258 - val_acc: 0.0156\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.8548 - acc: 0.0156 - val_loss: 0.7227 - val_acc: 0.0156\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.8506 - acc: 0.0156 - val_loss: 0.7219 - val_acc: 0.0156\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.8479 - acc: 0.0156 - val_loss: 0.7197 - val_acc: 0.0156\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.8450 - acc: 0.0156 - val_loss: 0.7183 - val_acc: 0.0156\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.8429 - acc: 0.0156 - val_loss: 0.7201 - val_acc: 0.0156\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.8407 - acc: 0.0156 - val_loss: 0.7163 - val_acc: 0.0156\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.8382 - acc: 0.0156 - val_loss: 0.7129 - val_acc: 0.0156\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.8370 - acc: 0.0156 - val_loss: 0.7133 - val_acc: 0.0156\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.8334 - acc: 0.0156 - val_loss: 0.7105 - val_acc: 0.0156\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 1s 64ms/step - loss: 0.8321 - acc: 0.0156 - val_loss: 0.7108 - val_acc: 0.0156\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.8304 - acc: 0.0156 - val_loss: 0.7079 - val_acc: 0.0156\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.8282 - acc: 0.0156 - val_loss: 0.7088 - val_acc: 0.0156\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.8266 - acc: 0.0156 - val_loss: 0.7110 - val_acc: 0.0156\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.8248 - acc: 0.0156 - val_loss: 0.7113 - val_acc: 0.0156\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.8225 - acc: 0.0156 - val_loss: 0.7061 - val_acc: 0.0156\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.8217 - acc: 0.0156 - val_loss: 0.7059 - val_acc: 0.0156\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.8200 - acc: 0.0156 - val_loss: 0.7054 - val_acc: 0.0156\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.8175 - acc: 0.0156 - val_loss: 0.7068 - val_acc: 0.0156\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.8172 - acc: 0.0156 - val_loss: 0.6997 - val_acc: 0.0156\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.8153 - acc: 0.0156 - val_loss: 0.6987 - val_acc: 0.0156\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.8141 - acc: 0.0156 - val_loss: 0.7003 - val_acc: 0.0156\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 0.8132 - acc: 0.0156 - val_loss: 0.7056 - val_acc: 0.0156\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([encoded_input,z,z],target_data,batch_size=128,epochs=30,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1BXnmK6CQKt"
   },
   "source": [
    "### Sampling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uflICs8suVjd"
   },
   "outputs": [],
   "source": [
    "input_test = keras.layers.Input(shape=(1,))\n",
    "x = emb(input_test)\n",
    "x,h,c = lstm(x,initial_state=[initial_h,initial_c])\n",
    "dense_1 = keras.layers.Dense(256,activation='relu')\n",
    "dense = dense_1(x)\n",
    "dense_2 = keras.layers.Dense(Num_Words,activation=\"softmax\")\n",
    "output = dense_2(dense)\n",
    "#output = dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "nM2R97GRCPQl"
   },
   "outputs": [],
   "source": [
    "sample_model = keras.models.Model([input_test,initial_h,initial_c],[output,h,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W27kufnG_qk"
   },
   "source": [
    "### Generate Sample Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KPmR9W8qIs2p"
   },
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "for i,w in enumerate(vect.get_vocabulary()):\n",
    "    word2idx[w]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auVrTn8kJHtn",
    "outputId": "1438ad2d-1f97-40bd-9fb5-5a5d000cafe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['starttoken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "jZUrOZUeOVf9"
   },
   "outputs": [],
   "source": [
    "max_poem_line_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wSun9QiIHkXp"
   },
   "outputs": [],
   "source": [
    "def sample_line():\n",
    "    np_input = np.array([[word2idx['starttoken']]])\n",
    "    h = np.zeros(shape=(1,LATENT_DIM))\n",
    "    c = np.zeros(shape=(1,LATENT_DIM))\n",
    "    output_line = []\n",
    "    for _ in range(max_poem_line_size):\n",
    "        o,h,c = sample_model.predict([np_input,h,c],verbose=0)\n",
    "        probs = o[0,0]\n",
    "        if np.argmax(probs) == 0:\n",
    "            print('oooooo')\n",
    "        probs[0] = 0\n",
    "        probs /= probs.sum()\n",
    "        idx = np.random.choice(len(probs),p=probs)\n",
    "        if idx == word2idx['endtoken']:\n",
    "            break\n",
    "        output_line.append(vect.get_vocabulary()[idx])\n",
    "        np_input[0,0] = idx\n",
    "    return ' '.join(output_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LKXU8AvQYrT",
    "outputId": "7cff5a06-39dc-45fe-8e2d-59a7ed8adf8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drown falling god hardest unkind choose scratch walk fast situation\n",
      "brought looking collided by wings watching instead insane distance flashing\n",
      "watching chase earn wake day woah fact pushing hurt lies\n",
      "which in fun crashing be but despair see remind honey\n",
      "---Generate another one [Y/N]y\n",
      "pretend owe verse bullshit secret standing seem soaking friend reflection\n",
      "clue closer dirty talk shouldnt almost see adele turning fallen\n",
      "things lets by it heavyhearted to seethrough weve none distance\n",
      "help mm word closly rest disappeared desperately what whispered older\n",
      "---Generate another one [Y/N]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for _ in range(4):\n",
    "        print(sample_line())\n",
    "    gen = input(\"---Generate another one [Y/N]\")\n",
    "    if gen and gen[0].lower().startswith('n'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML_AI",
   "language": "python",
   "name": "ml_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
